{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06a2c093",
   "metadata": {},
   "source": [
    "## Initial Data Cleaning ##\n",
    "\n",
    "Collects and unifies primary and secondary school data where the anonymized student is present in both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9dbc76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b942c53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Avaluacio_de_quart_dEducacio_Secundaria_Obligatoria_20251113.csv',\n",
       " 'Avaluacio_de_sise_deducacio_primaria_20251113.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check files in the Raw Data folder\n",
    "os.listdir('../Data/Raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fdb9617",
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv_path = os.path.abspath(\"../Data/Raw/Avaluacio_de_quart_dEducació_Secundaria_Obligatoria_20251111.csv\")\n",
    "\n",
    "# GENERAL OPTION: Take the first file in the Raw Data folder\n",
    "csv_path = os.path.join('../Data/Raw', os.listdir('../Data/Raw')[0])\n",
    "\n",
    "secondary_data = []\n",
    "with open(csv_path) as data: \n",
    "    reader = csv.reader(data)\n",
    "    for row in reader:\n",
    "        secondary_data.append(row)\n",
    "    data.close()\n",
    "df_S = pd.DataFrame(secondary_data)\n",
    "\n",
    "# Second file in the Raw Data folder\n",
    "csv_path = os.path.join('../Data/Raw', os.listdir('../Data/Raw')[1])\n",
    "primary_data = []\n",
    "with open(csv_path) as data: \n",
    "    reader = csv.reader(data)\n",
    "    for row in reader:\n",
    "        primary_data.append(row)\n",
    "    data.close()\n",
    "df_P = pd.DataFrame(primary_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c00a517e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_P.columns = df_P.iloc[0]    # set first row as header\n",
    "df_P = df_P[1:]                # drop the first row (since it's now the header)\n",
    "df_P.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_S.columns = df_S.iloc[0]    # set first row as header\n",
    "df_S = df_S[1:]                # drop the first row (since it's now the header)\n",
    "df_S.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00de7551",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'CODI_ALUMNE': pd.concat([df_P['CODI_ALUMNE'], df_S['CODI_ALUMNE']]).unique()})\n",
    "df['in_P'] = df['CODI_ALUMNE'].isin(df_P['CODI_ALUMNE']) \n",
    "df['in_S'] = df['CODI_ALUMNE'].isin(df_S['CODI_ALUMNE'])\n",
    "matching = df[df['in_P'] & df['in_S']] \n",
    "\n",
    "# Keep only rows from df_P where CODI_ALUMNE exists in both\n",
    "df_P_matching = df_P[df_P['CODI_ALUMNE'].isin(matching['CODI_ALUMNE'])].copy()\n",
    "# Keep only rows from df_S where CODI_ALUMNE exists in both\n",
    "df_S_matching = df_S[df_S['CODI_ALUMNE'].isin(matching['CODI_ALUMNE'])].copy()\n",
    "\n",
    "df_P_matching.reset_index(drop=True, inplace=True)\n",
    "df_S_matching.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "693118a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_cols = set(df_P_matching.columns) & set(df_S_matching.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "076de105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ANY', 'CODI_ALUMNE', 'PCAT', 'PCAT_CL', 'PCAT_EE', 'PCAST', 'PCAST_CL',\n",
      "       'PCAST_EE', 'PMAT', 'PMAT_NC', 'PMAT_EFM', 'PMAT_CR', 'PANG', 'PANG_CO',\n",
      "       'PANG_CE', 'PFRAN', 'PFRAN_CO', 'PFRAN_CE', 'PANG_EE', 'PFRAN_EE',\n",
      "       'PCAT_CO', 'PCAST_CO', 'PMED', 'PMED_COMP1', 'PMED_COMP2', 'PMED_COMP3',\n",
      "       'GENERE', 'MES_NAIXEMENT', 'ANY_NAIXEMENT', 'AREA_TERRITORIAL',\n",
      "       'NATURALESA', 'HABITAT'],\n",
      "      dtype='object', name=0)\n",
      "Index(['ANY', 'CODI_ALUMNE', 'PCAT', 'PCAT_CL', 'PCAT_EE', 'PCAST', 'PCAST_CL',\n",
      "       'PCAST_EE', 'PANG', 'PANG_CO', 'PANG_CL', 'PANG_EE', 'PFRAN',\n",
      "       'PFRAN_CO', 'PFRAN_CL', 'PFRAN_EE', 'PMAT', 'PMAT_EFM', 'PMAT_CR',\n",
      "       'PMAT_EST', 'PMAT_NC', 'PALE', 'PALE_CO', 'PALE_CL', 'PALE_EE', 'PCIEN',\n",
      "       'PCIEN_COMP1', 'PCIEN_COMP2', 'PCIEN_COMP3', 'PCIEN_COMP4', 'GENERE',\n",
      "       'MES_NAIXEMENT', 'ANY_NAIXEMENT', 'NATURALESA', 'AREA TERRITORIAL',\n",
      "       'HABITAT'],\n",
      "      dtype='object', name=0)\n"
     ]
    }
   ],
   "source": [
    "print(df_P.columns)\n",
    "print(df_S.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c3249b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of required columns (from your message)\n",
    "required_cols = [\n",
    "    'ANY', 'ANY_NAIXEMENT', 'CODI_ALUMNE', 'GENERE', 'HABITAT',\n",
    "    'MES_NAIXEMENT', 'NATURALESA', 'PANG', 'PANG_CO', 'PANG_EE',\n",
    "    'PCAST', 'PCAST_CL', 'PCAST_EE', 'PCAT', 'PCAT_CL', 'PCAT_EE',\n",
    "    'PFRAN', 'PFRAN_CO', 'PFRAN_EE', 'PMAT', 'PMAT_CR', 'PMAT_EFM', 'PMAT_NC'\n",
    "]\n",
    "\n",
    "df_P_clean = df_P.dropna(subset=required_cols).copy()\n",
    "df_S_clean = df_S.dropna(subset=required_cols).copy()\n",
    "\n",
    "common_ids = set(df_P_clean['CODI_ALUMNE']) & set(df_S_clean['CODI_ALUMNE'])\n",
    "df_P_clean = df_P_clean[df_P_clean['CODI_ALUMNE'].isin(common_ids)]\n",
    "df_S_clean = df_S_clean[df_S_clean['CODI_ALUMNE'].isin(common_ids)]\n",
    "\n",
    "df_P_clean['snapshot'] = 'past'\n",
    "df_S_clean['snapshot'] = 'present'\n",
    "\n",
    "df_combined = pd.concat([df_P_clean, df_S_clean], ignore_index=True)\n",
    "\n",
    "df_pivot = df_combined.pivot_table(\n",
    "    index='CODI_ALUMNE',\n",
    "    columns='snapshot',\n",
    "    values=[col for col in required_cols if col != 'CODI_ALUMNE'],\n",
    "    aggfunc='first'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1db36e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">ANY</th>\n",
       "      <th colspan=\"2\" halign=\"left\">ANY_NAIXEMENT</th>\n",
       "      <th colspan=\"2\" halign=\"left\">GENERE</th>\n",
       "      <th colspan=\"2\" halign=\"left\">HABITAT</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MES_NAIXEMENT</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">PFRAN_EE</th>\n",
       "      <th colspan=\"2\" halign=\"left\">PMAT</th>\n",
       "      <th colspan=\"2\" halign=\"left\">PMAT_CR</th>\n",
       "      <th colspan=\"2\" halign=\"left\">PMAT_EFM</th>\n",
       "      <th colspan=\"2\" halign=\"left\">PMAT_NC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>snapshot</th>\n",
       "      <th>past</th>\n",
       "      <th>present</th>\n",
       "      <th>past</th>\n",
       "      <th>present</th>\n",
       "      <th>past</th>\n",
       "      <th>present</th>\n",
       "      <th>past</th>\n",
       "      <th>present</th>\n",
       "      <th>past</th>\n",
       "      <th>present</th>\n",
       "      <th>...</th>\n",
       "      <th>past</th>\n",
       "      <th>present</th>\n",
       "      <th>past</th>\n",
       "      <th>present</th>\n",
       "      <th>past</th>\n",
       "      <th>present</th>\n",
       "      <th>past</th>\n",
       "      <th>present</th>\n",
       "      <th>past</th>\n",
       "      <th>present</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CODI_ALUMNE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>2018</td>\n",
       "      <td>2019</td>\n",
       "      <td>2005</td>\n",
       "      <td></td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>MÃ©s de 100000</td>\n",
       "      <td>MÃ©s de 100000</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>91,49</td>\n",
       "      <td></td>\n",
       "      <td>100,00</td>\n",
       "      <td></td>\n",
       "      <td>81,82</td>\n",
       "      <td></td>\n",
       "      <td>92,86</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100028145</th>\n",
       "      <td>2018</td>\n",
       "      <td>2022</td>\n",
       "      <td>2005</td>\n",
       "      <td>2005</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>MÃ©s de 100000</td>\n",
       "      <td>MÃ©s de 100000</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>76,89</td>\n",
       "      <td>43,33</td>\n",
       "      <td>88,89</td>\n",
       "      <td>66,67</td>\n",
       "      <td>81,82</td>\n",
       "      <td>33.33</td>\n",
       "      <td>57,14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000332771</th>\n",
       "      <td>2016</td>\n",
       "      <td>2020</td>\n",
       "      <td>2004</td>\n",
       "      <td>2004</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>De 10001 a 100000</td>\n",
       "      <td>De 10001 a 100000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>91,59</td>\n",
       "      <td>79,8</td>\n",
       "      <td>100,00</td>\n",
       "      <td>88,89</td>\n",
       "      <td>91,67</td>\n",
       "      <td>70</td>\n",
       "      <td>84,30</td>\n",
       "      <td>71,43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000343103</th>\n",
       "      <td>2016</td>\n",
       "      <td>2020</td>\n",
       "      <td>2004</td>\n",
       "      <td>2004</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>De 10001 a 100000</td>\n",
       "      <td>De 10001 a 100000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>97,28</td>\n",
       "      <td>74,88</td>\n",
       "      <td>100,00</td>\n",
       "      <td>77,78</td>\n",
       "      <td>100,00</td>\n",
       "      <td>90</td>\n",
       "      <td>92,22</td>\n",
       "      <td>42,86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000354325</th>\n",
       "      <td>2016</td>\n",
       "      <td>2020</td>\n",
       "      <td>2004</td>\n",
       "      <td>2004</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>De 10001 a 100000</td>\n",
       "      <td>De 10001 a 100000</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>94,20</td>\n",
       "      <td>97,5</td>\n",
       "      <td>100,00</td>\n",
       "      <td>100</td>\n",
       "      <td>83,43</td>\n",
       "      <td>90</td>\n",
       "      <td>100,00</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999005478</th>\n",
       "      <td>2016</td>\n",
       "      <td>2020</td>\n",
       "      <td>2004</td>\n",
       "      <td>2004</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>De 10001 a 100000</td>\n",
       "      <td>De 10001 a 100000</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>82,39</td>\n",
       "      <td>45,08</td>\n",
       "      <td>88,49</td>\n",
       "      <td>22,22</td>\n",
       "      <td>75,34</td>\n",
       "      <td>20</td>\n",
       "      <td>84,23</td>\n",
       "      <td>71,43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999027032</th>\n",
       "      <td>2016</td>\n",
       "      <td>2020</td>\n",
       "      <td>2004</td>\n",
       "      <td>2004</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>De 10001 a 100000</td>\n",
       "      <td>De 10001 a 100000</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>82,84</td>\n",
       "      <td>59,48</td>\n",
       "      <td>88,49</td>\n",
       "      <td>66,67</td>\n",
       "      <td>91,43</td>\n",
       "      <td>30</td>\n",
       "      <td>69,41</td>\n",
       "      <td>85,71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99949376</th>\n",
       "      <td>2016</td>\n",
       "      <td>2020</td>\n",
       "      <td>2004</td>\n",
       "      <td>2004</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>MÃ©s de 100000</td>\n",
       "      <td>MÃ©s de 100000</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>97,09</td>\n",
       "      <td>82,82</td>\n",
       "      <td>100,00</td>\n",
       "      <td>88,89</td>\n",
       "      <td>91,67</td>\n",
       "      <td>90</td>\n",
       "      <td>100,00</td>\n",
       "      <td>85,71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99961597</th>\n",
       "      <td>2019</td>\n",
       "      <td>2023</td>\n",
       "      <td>2007</td>\n",
       "      <td>2007</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>MÃ©s de 100000</td>\n",
       "      <td>MÃ©s de 100000</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>81,57</td>\n",
       "      <td>70,86</td>\n",
       "      <td>77,78</td>\n",
       "      <td>87,5</td>\n",
       "      <td>81,82</td>\n",
       "      <td>62.5</td>\n",
       "      <td>85,71</td>\n",
       "      <td>55,56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99983150</th>\n",
       "      <td>2018</td>\n",
       "      <td>2022</td>\n",
       "      <td>2006</td>\n",
       "      <td>2006</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>MÃ©s de 100000</td>\n",
       "      <td>MÃ©s de 100000</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>90,79</td>\n",
       "      <td>49,17</td>\n",
       "      <td>88,89</td>\n",
       "      <td>33,33</td>\n",
       "      <td>90,91</td>\n",
       "      <td>33.33</td>\n",
       "      <td>92,86</td>\n",
       "      <td>62,5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>251748 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0             ANY         ANY_NAIXEMENT         GENERE          \\\n",
       "snapshot     past present          past present   past present   \n",
       "CODI_ALUMNE                                                      \n",
       "             2018    2019          2005              H       D   \n",
       "100028145    2018    2022          2005    2005      D       D   \n",
       "1000332771   2016    2020          2004    2004      H       H   \n",
       "1000343103   2016    2020          2004    2004      D       D   \n",
       "1000354325   2016    2020          2004    2004      D       D   \n",
       "...           ...     ...           ...     ...    ...     ...   \n",
       "999005478    2016    2020          2004    2004      H       H   \n",
       "999027032    2016    2020          2004    2004      H       H   \n",
       "99949376     2016    2020          2004    2004      D       D   \n",
       "99961597     2019    2023          2007    2007      H       H   \n",
       "99983150     2018    2022          2006    2006      D       D   \n",
       "\n",
       "0                      HABITAT                    MES_NAIXEMENT          ...  \\\n",
       "snapshot                  past            present          past present  ...   \n",
       "CODI_ALUMNE                                                              ...   \n",
       "                MÃ©s de 100000     MÃ©s de 100000             1          ...   \n",
       "100028145       MÃ©s de 100000     MÃ©s de 100000             7       7  ...   \n",
       "1000332771   De 10001 a 100000  De 10001 a 100000             1       1  ...   \n",
       "1000343103   De 10001 a 100000  De 10001 a 100000             1       1  ...   \n",
       "1000354325   De 10001 a 100000  De 10001 a 100000            10      10  ...   \n",
       "...                        ...                ...           ...     ...  ...   \n",
       "999005478    De 10001 a 100000  De 10001 a 100000            11      11  ...   \n",
       "999027032    De 10001 a 100000  De 10001 a 100000             9       9  ...   \n",
       "99949376        MÃ©s de 100000     MÃ©s de 100000             7       7  ...   \n",
       "99961597        MÃ©s de 100000     MÃ©s de 100000             7       7  ...   \n",
       "99983150        MÃ©s de 100000     MÃ©s de 100000            10      10  ...   \n",
       "\n",
       "0           PFRAN_EE           PMAT         PMAT_CR         PMAT_EFM          \\\n",
       "snapshot        past present   past present    past present     past present   \n",
       "CODI_ALUMNE                                                                    \n",
       "                              91,49          100,00            81,82           \n",
       "100028145                     76,89   43,33   88,89   66,67    81,82   33.33   \n",
       "1000332771                    91,59    79,8  100,00   88,89    91,67      70   \n",
       "1000343103                    97,28   74,88  100,00   77,78   100,00      90   \n",
       "1000354325                    94,20    97,5  100,00     100    83,43      90   \n",
       "...              ...     ...    ...     ...     ...     ...      ...     ...   \n",
       "999005478                     82,39   45,08   88,49   22,22    75,34      20   \n",
       "999027032                     82,84   59,48   88,49   66,67    91,43      30   \n",
       "99949376                      97,09   82,82  100,00   88,89    91,67      90   \n",
       "99961597                      81,57   70,86   77,78    87,5    81,82    62.5   \n",
       "99983150                      90,79   49,17   88,89   33,33    90,91   33.33   \n",
       "\n",
       "0           PMAT_NC          \n",
       "snapshot       past present  \n",
       "CODI_ALUMNE                  \n",
       "              92,86          \n",
       "100028145     57,14       0  \n",
       "1000332771    84,30   71,43  \n",
       "1000343103    92,22   42,86  \n",
       "1000354325   100,00     100  \n",
       "...             ...     ...  \n",
       "999005478     84,23   71,43  \n",
       "999027032     69,41   85,71  \n",
       "99949376     100,00   85,71  \n",
       "99961597      85,71   55,56  \n",
       "99983150      92,86    62,5  \n",
       "\n",
       "[251748 rows x 44 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ac13e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251748"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f0dca81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251748"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83db177a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ANY',\n",
       " 'ANY_NAIXEMENT',\n",
       " 'CODI_ALUMNE',\n",
       " 'GENERE',\n",
       " 'HABITAT',\n",
       " 'MES_NAIXEMENT',\n",
       " 'NATURALESA',\n",
       " 'PANG',\n",
       " 'PANG_CO',\n",
       " 'PANG_EE',\n",
       " 'PCAST',\n",
       " 'PCAST_CL',\n",
       " 'PCAST_EE',\n",
       " 'PCAT',\n",
       " 'PCAT_CL',\n",
       " 'PCAT_EE',\n",
       " 'PFRAN',\n",
       " 'PFRAN_CO',\n",
       " 'PFRAN_EE',\n",
       " 'PMAT',\n",
       " 'PMAT_CR',\n",
       " 'PMAT_EFM',\n",
       " 'PMAT_NC'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e51ff90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_P_matching: files = 700990  unique students = 251748\n",
      "df_S_matching: files = 489510  unique students = 251748\n"
     ]
    }
   ],
   "source": [
    "# One-to-one merge by CODI_ALUMNE eliminating duplicates\n",
    "\n",
    "print(\"df_P_matching: files =\", len(df_P_matching),\n",
    "      \" unique students =\", df_P_matching['CODI_ALUMNE'].nunique())\n",
    "\n",
    "print(\"df_S_matching: files =\", len(df_S_matching),\n",
    "      \" unique students =\", df_S_matching['CODI_ALUMNE'].nunique())\n",
    "\n",
    "df_P_unique = df_P_matching.sort_values('CODI_ALUMNE').drop_duplicates('CODI_ALUMNE')\n",
    "df_S_unique = df_S_matching.sort_values('CODI_ALUMNE').drop_duplicates('CODI_ALUMNE')\n",
    "\n",
    "df_merged = pd.merge(\n",
    "    df_P_unique,\n",
    "    df_S_unique,\n",
    "    on='CODI_ALUMNE',\n",
    "    how='inner',           # only keep rows present in both\n",
    "    suffixes=('_P', '_S'), # distinguish the two sets of columns\n",
    "    validate='one_to_one'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469b8630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnes de notes trobades:\n",
      "['PCAT_P', 'PCAT_CL_P', 'PCAT_EE_P', 'PCAST_P', 'PCAST_CL_P', 'PCAST_EE_P', 'PMAT_P', 'PMAT_NC_P', 'PMAT_EFM_P', 'PMAT_CR_P', 'PANG_P', 'PANG_CO_P', 'PANG_CE', 'PFRAN_P', 'PFRAN_CO_P', 'PFRAN_CE', 'PANG_EE_P', 'PFRAN_EE_P', 'PCAT_CO', 'PCAST_CO', 'PMED', 'PMED_COMP1', 'PMED_COMP2', 'PMED_COMP3', 'PCAT_S', 'PCAT_CL_S', 'PCAT_EE_S', 'PCAST_S', 'PCAST_CL_S', 'PCAST_EE_S', 'PANG_S', 'PANG_CO_S', 'PANG_CL', 'PANG_EE_S', 'PFRAN_S', 'PFRAN_CO_S', 'PFRAN_CL', 'PFRAN_EE_S', 'PMAT_S', 'PMAT_EFM_S', 'PMAT_CR_S', 'PMAT_EST', 'PMAT_NC_S', 'PALE', 'PALE_CO', 'PALE_CL', 'PALE_EE', 'PCIEN', 'PCIEN_COMP1', 'PCIEN_COMP2', 'PCIEN_COMP3', 'PCIEN_COMP4']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1) Detectar totes les columnes de notes (comencen per \"P\")\n",
    "note_cols_all = [c for c in df_merged.columns if c.startswith('P')]\n",
    "\n",
    "# Per seguretat, assegurem que PMAT_P i PMAT_S hi siguin\n",
    "print(\"Columnes de notes trobades:\")\n",
    "print(note_cols_all)\n",
    "\n",
    "# 2) Convertir totes les notes a numèriques (coma → punt, string → float)\n",
    "for col in note_cols_all:\n",
    "    # Pas 1: assegurar tipus string\n",
    "    s = df_merged[col].astype(str)\n",
    "    # Pas 2: substituir comes per punts\n",
    "    s = s.str.replace(',', '.', regex=False)\n",
    "    # Pas 3: convertir a numèric, valors no convertibles → NaN\n",
    "    df_merged[col] = pd.to_numeric(s, errors='coerce')\n",
    "\n",
    "# 3) Separar matemàtiques i resta de notes\n",
    "math_cols = ['PMAT_P', 'PMAT_S']\n",
    "other_note_cols = [c for c in note_cols_all if c not in math_cols]\n",
    "\n",
    "# 4) Calcular correlacions de matemàtiques amb la resta\n",
    "corr_with_mat_P = df_merged[other_note_cols + ['PMAT_P']].corr(numeric_only=True)['PMAT_P'].sort_values(ascending=False)\n",
    "corr_with_mat_S = df_merged[other_note_cols + ['PMAT_S']].corr(numeric_only=True)['PMAT_S'].sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nCorrelacions amb Matemàtiques P (PMAT_P):\")\n",
    "print(corr_with_mat_P)\n",
    "\n",
    "print(\"\\nCorrelacions amb Matemàtiques S (PMAT_S):\")\n",
    "print(corr_with_mat_S)\n",
    "\n",
    "# 5) Scatter plots: Matemàtiques vs. resta de notes\n",
    "#    Per no morir en el plot, agafem una mostra aleatòria de, per exemple, 10.000 alumnes\n",
    "max_points = 10000\n",
    "if len(df_merged) > max_points:\n",
    "    df_plot = df_merged.sample(n=max_points, random_state=0)\n",
    "else:\n",
    "    df_plot = df_merged\n",
    "\n",
    "for m in math_cols:\n",
    "    for col in other_note_cols:\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.scatter(df_plot[col], df_plot[m], alpha=0.2, s=5)\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel(m)\n",
    "        plt.title(f\"{m} vs {col}\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
